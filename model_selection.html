<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Topic 1</title>
    <link rel="stylesheet" href="styles.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>

    <header>
        <h1>モデル、ハイパーパラメータの選択</h1>
        <nav>
            <ul>
                <li><a href="index.html" class="special-link">Back to Home</a></li>
            </ul>
        </nav>
        <nav>
            <ul>
                <li><a href="regularization.html" >＜前へ：正則化</a></li>
                <li><a href="Gaussian_process.html" >＞次へ：ガウス過程</a></li>
            </ul>
        </nav>
    </header>


    <div>
        <h2>モデル、ハイパーパラメータの選択</h2>
        <p>
            モデルが多項式の場合、何次式にしてどれくらいモデルを複雑にするのがいいのかという疑問がある。
            また、正則化したときには正則化係数\(\lambda\)を決める必要があるし、
            ニューラルネットワークなどのもっと複雑なモデルでは複雑さを支配する複数のパラメータがありえる。
        </p>
        <p>
            新しいデータに対して良い予想ができるようにそのようなパラメータあを決めたい。
            また、異なるモデル同士を比較して、どれが一番よさそうか知りたい。
        </p>
        <h2>検証誤差</h2>
        <p>
            誤差と言ったときに、次の３つの誤差について区別して考える必要がある。
            まず、手元にあるデータへの誤差として訓練誤差\(E_{train}(\lambda)\)がある。
            モデルの良さを表すのに本質的なのは、手元にない道のデータへの誤差である汎用誤差\(E_{gen}(\lambda)\)である。
            学習の目的はこの汎化誤差をなるべく下げることである。
            しかし、この値は知ることはできないので、代わりに手元にあるデータをもちいて以下のように検証誤差\(E_{valild}(\lambda)\)を評価する。
        </p>
        <p>
            訓練データでは過学習などが起こりえるし、良い予測ができるのは当たり前である。
            そこで、最適なハイパーパラメータを決めるために、確認用集合（検証用集合）を用いて、
            最終的にどのモデルがよいか比較、決定するためにテスト集合を別に用意しておくことが理想的である。
        </p>
        <p>
            しかし、実際にはデータが十分リッチにあるとは限らないので、訓練、検証、テストの3分割を行う代わりに、次のような工夫が行われる。
        </p>

        <h3>K-fold 交差検証法（cross-validation）</h3>
        <p>これは一番よく用いられる方法である。</p>
        <p>データをＫ個のサブセットに分け、Ｋ－１個のサブセットを用いて訓練を行い、残りの１セットで誤差を評価する。
            この操作をＫ通りすべてに行い、Ｋ個の誤差の平均を検証誤差とする。</p>
        <h3>LOO法（leave-one-out method）</h3>
        <p>特にKをデータ点の数Nとしたときは、1個抜き法、LOO法と呼ばれる。データが特に少ないとき、このようにする。</p>

        <h2>エビデンス近似（経験ベイズ法）</h2>
        <p>パラメータ\(\mathbf{w}\)もベイズ的に扱うことを考える。
            そのために、ハイパーパラメータについても事前分布を導入する。
            ちなみに、ハイパーパラメータとはモデルパラメータの分布を制御するパラメータのことである。
        </p>
        <p>まず、尤度関数は「線形回帰」の回で見た通り、次のようにあらわせる。ただし、\(\mathbf{X}\)は省略している。
        </p>
        $$ p(\mathbf{t}|\mathbf{w},\beta) =  \mathcal{N}(\mathbf{t} | \mathbf{w}^T \phi,\beta^{-1}) $$
        <p>次に、パラメータ\(\mathbf{w}\)もベイズ的に扱い、ハイパーパラメータ\(\alpha\)を用いて事前分布は以下の通りに表せる。</p>
        $$ p(\mathbf{w}|\alpha) = \mathcal{N}( \mathbf{w}|0, \alpha^{-1} \mathbf{I}) $$
        <p>このとき事後分布は以下の通りに表せる。</p>
        $$ p(\mathbf{w}|\mathbf{t}, \alpha, \beta) = \frac{p( \mathbf{t} | \mathbf{w}, \beta ) p(\mathbf{w}| \alpha)}{p(\mathbf{t}|\alpha, \beta)} $$
        <p>ここで注目したいのは規格化のためにある右辺の分母である。
            これは周辺尤度関数であり、パラメータ\(\mathbf{w}\)に関してのみ積分して次のように得られる。</p>
        $$ p(\mathbf{t}|\alpha, \beta) = \int p(\mathbf{t}|\mathbf{w}, \beta) p(\mathbf{w}| \alpha) d\mathbf{w} $$
        <p>この周辺尤度関数を最大化するようにハイパーパラメータの値を決めればよい。</p>
        <p>実際には周辺尤度関数\(p(\mathbf{t}|\alpha, \beta)\)の対数を取って書き下す。それはエビデンス関数と呼ばれる。
            エビデンス関数を最大化するようにハイパーパラメータを決めればよい。</p>

        <h2>情報量規準</h2>
        <p>
            これまで見てきた二つの方法、交差検証法と経験ベイズ法を振り返ってみよう。
            これらの方法はともに計算的負荷が高い。
            具体的には、交差検証法では分割数だけモデルの学習を繰り返さなければいけない。
            また、経験ベイズ法は周辺尤度の厳密評価は計算が困難である。
        </p>
        <p>
            そこで、計算的負荷が低い方法として、情報量規準というものがある。
            これは学習モデルになんらかの仮定をいれることで、本質的な\(E_{gen}\)を解析的に見積もる方法である。
            しかし、デメリットとして仮定を入れる必要があるので、使える場面が限定的である。
        </p>
        <p>
            有名な情報量規準として、赤池情報規準（AIC）や、ベイズ情報量規準（BIC）がある。
        </p>

    </div>


    <hr>

    <div>
        <h2>実装の例</h2>
        <p>以下は、糖尿病にどれくらいなりやすいか予測するためのLASSOで正則化した線形回帰モデルであり、
            正則化係数を選ぶために交差検証法（cross-validation）を用いてハイパーパラメータの選択を行っている。</p>
    </div>

    <div class="github-link">
        <a href="https://github.com/HanaHirose/ML_Self_Study/tree/main/LASSO_K-fold_CrossVal_Diabetes" target="_blank">
            <div class="link-header">
                <img src="https://github.com/favicon.ico" alt="GitHub Logo">
                <span>GitHub：糖尿病データにおけるLASSOで正則化した線形回帰モデルの交差検証法によるハイパーパラメータの選択</span><br>    
            </div>
            <p class="link-url">https://github.com/HanaHirose/ML_Self_Study/tree/main/LASSO_K-fold_CrossVal_Diabetes</p>
        </a>
    </div>

    <footer>
        <nav>
            <ul>
                <li><a href="regularization.html" >＜前へ：正則化</a></li>
                <li><a href="Gaussian_process.html" >＞次へ：ガウス過程</a></li>
            </ul>
        </nav>
        <nav>
            <ul>
                <li><a href="index.html" class="special-link">Back to Home</a></li>
            </ul>
        </nav>

        <p>© 2024 Hana Hirose. All rights reserved.</p>
    </footer>
</body>
</html>