<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>機械学習の勉強部屋</title>
    <link rel="stylesheet" href="styles.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <header>
        <h1>サポートベクトルマシン（ソフトマージン）</h1>
        <nav>
            <ul>
                <li><a href="index.html" class="special-link">Back to Home</a></li>
            </ul>
        </nav>
        <nav>
            <ul>
                <li><a href="SupportVectorMachine.html" >＜前へ：サポートベクトルマシン</a></li>
                
            </ul>
        </nav>
    </header>
    <div>
        <h2>ソフトマージン</h2>
        <h3>過学習を防ぐには</h3>
        <p>
            前ページでは訓練データが特徴空間において線形分離可能であることを仮定してきた。しかし、現実には完璧に分離できずクラスの条件付き確率分布が重なる場合もある。
            そのような場合に無理して完全な線形分離を求めると、過学習が生じて汎化性能を悪化させてしまう。
            そこで、誤りを適当に許容させて学習させることが重要である。これはパーセプトロンの時代にはできなかったことである。
        </p>
        <h3>ソフトマージン</h3>
        <p>
            過学習を防ぐために、制約を満たさない条件は許さない（ハードマージン）のではなく、許すがその代わり罰金を加える（ソフトマージン）という手法がある。
        </p>
        <p>
            ハードマージンでは誤って分類したデータについては無限大のペナルティを与え、正しく分類したデータにはペナルティを与えない誤差関数を暗に用いて、マージンを最大化するようにパラメータを最適化している。
            これを変更して、データがマージン内に侵入した時は、マージン境界からの距離に応じてペナルティを与えることで、マージン境界の「間違った側」に存在することを許すように修正することを考える。
        </p>
        <p>
            具体的には、まずスラック変数\(\xi_n \geqslant 0 (n=1, \dots N)\)を導入する。
            スラック変数は各訓練データごとに定義される変数で、データが正しく分類されてかつマージンの境界上か外側に存在するときは\(\xi_n=0\)、
            それ以外の場合には\(\xi_n=|t_n-y_n(\mathbf{x}_n)|\)として定義される。したがって、ちょうど分類境界\(y(\mathbf{x})=0\)にあるデータについては\(\xi_n=1\)、
            誤分類されたデータについては\(\xi_n>1\)が成り立つ。
        </p>
    </div>

    </div>
    <div class="gallery">
        <figure>
            <img src="figures/Figure7.3.jpg" alt="ソフトマージン" width="400">
            <figcaption>Figure 1: ソフトマージン（C.M. Bishop, PRML, 2006）</figcaption>
        </figure>
    </div>

    <div>
        <p>
            上図のように、\(\xi_n=0\)となるデータは正しく分類されており、かつマージンの境界の上か正しい側にある。また、\(0<\xi_n \leqslant 1\)となるデータはマージンの内側にあるが正しく分類されている。
            そして、\(\xi_n>1\)となるデータは分類境界に足して誤った側にあり、誤分類されている。
        </p>
        <h3>解くべき問題</h3>
        <p>
            ペナルティを課すことを反映して、制約条件のもとに最小化する目的関数は次のように変更される。
        </p>
        $$ \underset{\mathbf{w},b,\mathbf{\xi}} {\operatorname{min}} \frac{1}{2} \| \mathbf{w} \|^2 + C \sum_{n=1}^N \xi_n
        \quad \operatorname{subj.to} \xi_n \geqslant 1- t_n ( \mathbf{w}^T \Phi (\mathbf{x}_n)+b) ,\quad \xi_n \geqslant 0 \quad (n=1, \dots , N) $$
        <p>
            ここで\(C>0\)はペナルティとマージンの大きさの間のトレードオフを制御するパラメータである。
            \(C\)は訓練エラーとモデルの複雑さのトレードオフを制御する正則化係数（の逆数）のような役割を果たしている。
            実際、\(C\to \infty\)の極限においては、分離可能なハードマージンSVMの最適化問題と等しくなる。
        </p>

        <h3>双対問題への書き換え</h3>
        <p>
            ハードマージンの時と同様にラグランジュ関数を作り、\(\mathbf{w},b,\mathbf{\xi}\)に関して１回微分を０とおいて停留条件をもとめて、ラグランジュ関数に代入してそれらの変数を消去すると、以下のような双対問題に書き換えられる。
        </p>
        $$ \underset{\mathbf{a}} {\operatorname{max}} \left\{ \sum_{n=1}^N a_n - \frac{1}{2} \sum_{n=1}^N a_n \sum_{m=1}^N a_n a_m t_n t_m k(\mathbf{x}_n,\mathbf{x}_m) \right\} $$
        $$ \operatorname{subj.to} C \geqslant a_n \geqslant 0 \quad (n=1, \dots , N), \quad  \sum_{n=1}^N t_n a_n =0 $$
        <p>
            上式をみてわかる通り、結局、ハードマージンとの違いは、\(a_n\)に上限の制約\(C\geqslant a_n\)がついただけである。
        </p>
        <h3>KKT条件の解釈</h3>
        <p>
            ラグランジュ関数から得られたKKT条件から、最終的に次のようなことが分かる。
        </p>
        <p>
            \(a_n=0\)となるデータ点は識別関数\(y(\mathbf{x})\)に何も影響を及ぼさない。それ以外の点がサポートベクトルになる。
            つまり、\(a_n>0\)となる点がサポートベクトルになるということである。
        </p>
        <p>
            \(0< a_n < C\)となるデータ点は\(\xi_n=0\)が成立するので、ちょうどマージン境界上に存在している。
        </p>
        <p>
            \(a_n=C\)となるデータ点はマージン内に侵入しており、\(\xi_n \leqslant 1\)の場合は正しく分類されているが、\(\xi_n > 1\)の場合は誤分類されている。
        </p>



    </div>





    <footer>
        <nav>
            <ul>
                <li><a href="SupportVectorMachine.html" >＜前へ：サポートベクトルマシン</a></li>
            </ul>
        </nav>
        <nav>
            <ul>
                <li><a href="index.html" class="special-link">Back to Home</a></li>
            </ul>
        </nav>

        <p>© 2024 Hana Hirose. All rights reserved.</p>
    </footer>
</body>
</html>