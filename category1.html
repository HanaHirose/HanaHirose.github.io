<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Topic 1</title>
    <link rel="stylesheet" href="styles.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <header>
        <h1>線形回帰</h1>
        <nav>
            <ul>
                <li><a href="index.html">Back to Home</a></li>
                <!-- <li><a href="category1.html">Back to Category 1</a></li> -->
            </ul>
        </nav>
    </header>
    <div>
        <h2>線形回帰とは</h2>
        <p>\(\mathbf{x} \in \mathbb{R}^D, \mathbf{t} \in \mathbb{R} \)</p>
        <p>ここで\(\mathbf{x}\)は説明変数（入力）、\(\mathbf{t}\)は応答変数、目的変数（出力）</p>
        <h3>回帰問題：やりたいこと</h3>
        <p>\(\mathbf{N}\)個の観測データ\( \{(\mathbf{x}_1,\mathbf{t}_1),(\mathbf{x}_2,\mathbf{t}_2), \dots ,(\mathbf{x}_N,\mathbf{t}_N) \} \)から\(\mathbf{x} \)と\(\mathbf{t}\)の関係をモデル化したい</p>
        <h3>線形回帰（Linear Regression）</h3>
        <p>最も単純な線形回帰モデルは入力変数の線形結合で\(\mathbf{t}\)を予測できるような関数\(y(\mathbf{x})\)を次のように構成することである。</p>
        $$ y(\mathbf{x},\mathbf{w})=w_0 + w_1 x_1 + w_2 x_2 + \dots + w_D x_D $$
        <p>ここで重要なのは、これはパラメータ\( \mathbf{w} \)に関して線形結合になっているという点である。だから"線形"回帰と呼ぶ。</p>
        <h3>線形基底関数モデルへの拡張</h3>
        <p>先ほどのままでは\(\mathbf{x} \)についても線形結合になっているため、表現力に乏しいモデルになっている。<br />
            そこで、入力変数に関して非線形な関数の線形結合を考えることで、このモデルを次のように拡張することができる。
        </p>
        $$ y (\mathbf{x},\mathbf{w}) = \sum_{j=0}^{M-1} w_j \phi_j(\mathbf{x}) = \mathbf{w}^T \phi(\mathbf{x}) $$
        <p>ここで、パラメータ\( \mathbf{w} = ( w_0, \dots, w_{M-1} )^T\)、基底関数 \(\phi = (\phi_0, \dots, \phi_{M-1}) \)である。<br />
        （\(\mathbf{x}\)自体はD次元だが、\(\mathbf{x}\)で構成された既定関数\(\phi\)は異なるM次元をもって良いことに注意）
        </p>
        <p>基底関数として\( \mathbf{x} \)の多項式を取るものの他に、
            よく使われる基底関数としては、例えば、以下のようなガウス基底関数がある。</p>
        $$ \phi_j(x) = exp\{-\frac{(x-\mu_j)^2)}{2s^2} \} $$
        <p>他には、次のようなシグモイド基底関数もある。</p>
        $$ \phi_j(x) = \frac{1}{1+ exp(\frac{x-\mu_j}{s})} $$
        <p>ただし、次の関数はロジスティックシグモイド関数（logistic sigmoid function）とよばれる。</p>
        $$ \sigma (a) = \frac{1}{1+ exp(-a)} $$
        <p>以下に各基底関数の様子を示す。（図：C.M. Bishop, PRML, 2006）</p>
    </div>
    <div class="gallery">
        <figure>
            <img src="figures/Figure3.1a.jpg" alt="多項式" width="300">
            <figcaption>Figure 1-1: 多項式</figcaption>
        </figure>
        <figure>
            <img src="figures/Figure3.1b.jpg" alt="ガウス基底関数" width="300">
            <figcaption>Figure 1-2: ガウス基底関数</figcaption>
        </figure>
        <figure>
            <img src="figures/Figure3.1c.jpg" alt="シグモイド関数" width="300">
            <figcaption>Figure 1-3: シグモイド関数</figcaption>
        </figure>
    </div>
    <footer>
        <p>© 2024 Hana Hirose. All rights reserved.</p>
    </footer>
</body>
</html>
