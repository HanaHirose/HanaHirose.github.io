<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>機械学習の勉強部屋</title>
    <link rel="stylesheet" href="styles.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <header>
        <h1>線形分離とパーセプトロン</h1>
        <nav>
            <ul>
                <li><a href="index.html" class="special-link">Back to Home</a></li>
            </ul>
        </nav>
        <nav>
            <ul>
                <li><a href="Gaussian_process2.html" >＜前へ：ガウス過程（続き）</a></li>
                <li><a href="Gaussian_process2.html" >＞次へ：ガウス過程（続き）</a></li>
            </ul>
        </nav>
    </header>
    
    <div>
        <h2>線形分離とは</h2>
        <p>２クラス分類問題を考える。２クラス分類とは、与えられた入力ベクトル\(\mathbf{x}\in\mathbb{R}^D\)に対してクラスラベル\(t\in\{0,1\}\)を付けることである。</p>
        <p>つまり、入力ベクトルの空間において、\(t=0\)にラベル付けされた領域と、\(t=1\)にラベル付けされた領域に分けることである。
        </p>
        <p>特に、D次元の超平面によって領域を分けることを「線形分離」という。</p>

        <h2>パーセプトロン</h2>
        <p>1958年にRosenblattが提案した一番初めの機械学習で、線形識別モデルである。</p>

    </div>

    <div class="gallery">
        <figure>
            <img src="figures/Perpeptron_picture.png" alt="パーセプトロン" width="600">
            <figcaption>Figure 1: パーセプトロンの写真（C. Bishop, PRMLより）</figcaption>
        </figure>
    </div>

    <div>
        <p>パーセプトロンは複数の信号を入力として受け取り、ニューロン（下図の丸）に送られる際に重みづけ\(\mathbf{w}\)をする。</p>
        <p>ニューロンでは送られてきた信号の総和が計算され、その総和が閾値\(\theta\)を超えたら「ニューロンが発火」つまり１を返す。</p>
    </div>

    <div class="gallery">
        <figure>
            <img src="figures/Preceptron.png" alt="パーセプトロン写真" width="300">
            <figcaption>Figure 2: パーセプトロン</figcaption>
        </figure>
    </div>

    <div>
        <p>
            これを式で表すと、以下のようにステップ関数を用いて表すことができる。
        </p>
        $$ y(\mathbf{x},\mathbf{w}) = \Theta(\mathbf{w}\cdot \mathbf{x} - \theta) $$
        <p>入出力関係の具体例を表すデータセットに基づいて、その関係を再現するパラメータ\(\mathbf{w},\theta\)を定めて学習する。</p>

    </div>

    <div>
        <h3>パーセプトロンの収束定理</h3>
        <p>
            線形分離可能な入出力関係の具体的なセットが与えられたとする。
            このとき、パーセプトロンは、パーセプトロンアルゴリズムにより、その関係を再現するパラメータ\(\mathbf{w},\theta\)を有限時間内で見つけることができると保証されている。
        </p>
        <h3>パーセプトロンの限界</h3>
        <p>残念ながら、一般の分類問題は線形分離可能ではない。その場合、パーセプトロンアルゴリズムは停止せず、準最適な解を見つける（つまり、少しの間違いは許すということ）こともできない。</p>
        <p>このような限界が明らかになったため、パーセプトロンブームは1960年代末に収束した。</p>
    </div>






    <footer>
        <nav>
            <ul>
                <li><a href="Gaussian_process2.html" >＜前へ：ガウス過程（続き）</a></li>
            </ul>
        </nav>
        <nav>
            <ul>
                <li><a href="index.html" class="special-link">Back to Home</a></li>
            </ul>
        </nav>

        <p>© 2024 Hana Hirose. All rights reserved.</p>
    </footer>
</body>
</html>