<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Topic 1</title>
    <link rel="stylesheet" href="styles.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</head>
<body>
    <header>
        <h1>ロジスティック回帰</h1>
        <nav>
            <ul>
                <li><a href="index.html" class="special-link">Back to Home</a></li>
            </ul>
        </nav>
        <nav>
            <ul>
                <li><a href="category1.html" >＜前へ：線形回帰</a></li>
            </ul>
        </nav>
    </header>
    <div>
        <h2>ロジスティック回帰とは</h2>
        <h3>２クラス分類問題</h3>
        <p>入力\(\mathbf{x}\in \mathbb{R}^D\)に対して、
            yes / No に対応する出力\(t \in \{ 0,1\} \)を与える問題を２クラス分類問題と呼ぶ。</p>
        <p>クラス\( C_1\)の事後確率は</p>
        $$ p (C_1 | \Phi) = y(\Phi) = \sigma( \mathbf{w}^T \Phi) $$
        <p>と書ける。ここで\(\sigma( \mathbf{w}^T \Phi) \)は次のように定義されるロジスティックシグモイド関数である。</p>
        $$ \sigma(a) = \frac{1}{1+ exp(-a)} $$
    </div>
    <div class="gallery">
        <figure>
            <img src="figures/Figure4.9.jpg" alt="ロジスティックシグモイド関数" width="300">
            <figcaption>Figure 1: ロジスティックシグモイド関数（C.M. Bishop, PRML, 2006）</figcaption>
        </figure>
    </div>
    <div>
        <p>このモデルを使って分類する方法をロジスティック回帰と呼ぶ。</p>
        <h3>交差エントロピー誤差関数（cross-entropy error function）</h3>
        <p>線形回帰の時のように最尤法でパラメータを決定したい。
            そのためにロジスティックシグモイド関数の微分を行うが、数学的知識としてロジスティックシグモイド関数の微分は次のような性質がある。
        </p>
        $$ \frac{d \sigma}{da} = \sigma(1- \sigma) $$
        <p>
            データ集合\(\{\Phi_n, t_n\}, t_n \in \{0,1\}\)であり、\(\Phi_n = \Phi(\mathbf{x}_n)\)で、
            これが\(n = 1,2, \dots , N\)に対して存在している。このとき尤度関数は
        </p>
        $$ p(\mathbf{t}|\mathbf{w}) = \prod_{n=1}^{N} p(C_1 | \Phi_n)^{t_n} \{ 1 - p(C_1 | \Phi_n) \}^{1-t_n} $$
        <p>と書ける。尤度の負の対数を取って以下のように誤差関数を定義する。</p>
        $$ E(\mathbf{w}) = - \ln p (\mathbf{t}|\mathbf{w}) = - \sum_{n=1}^{N} \{ t_n \ln p(C_1|\Phi_n) + (1- t_n) \ln (1-p(C_1|\Phi_n) )  \} $$
        <p>
            これは交差エントロピー誤差関数と呼ばれる。これを最小化することを考えてパラメータを決定する。
        </p>
        <p>
            残念ながら、これについての最尤解を解析的に求めることはできないので、数値的に求める。その具体的な方法として次の二つを紹介する。    
        </p>
        <h3>勾配法</h3>
        <p>目的関数\(E(\mathbf{w})\)に対して、以下の反復で\(E(\mathbf{w})\)を最小化する</p>
        $$ \left. \mathbf{w}_{\tau+1} = \mathbf{w}_{\tau} - \eta \frac{\partial E(\mathbf{w})}{\partial \mathbf{w}}\right|_{\mathbf{w}=\mathbf{w}_\tau} $$
        <p>ただし、\(\eta > 0\)は十分小さな正数。これを繰り返すと\(E(\mathbf{w})\)を最小化できることは数学的に保証されている。</p>
        <p>この方法の特徴は計算量が小さくて済むこと。ただし、収束が遅く、更新幅\(\eta\)を自分で適切に与えてやる必要がある。また、大域最小解が求まる保証はない。</p>
        <h3>ニュートン法</h3>
        <p>先ほどは1次まで用いたが、今度は目的関数\(E(\mathbf{w})\)をテイラー展開して2次までもちいる。得られた2次形式の最適化を繰り返す。</p>
        $$ \left. \mathbf{w}_{\tau+1} = \mathbf{w}_{\tau} - (\frac{\partial^2 E(\mathbf{w})}{\partial \mathbf{w} \partial \mathbf{w}} \right|_{\mathbf{w}=\mathbf{w}_\tau})^{-1} \left. \frac{\partial E(\mathbf{w})}{\partial \mathbf{w}}\right|_{\mathbf{w}=\mathbf{w}_\tau} $$
        <p>この方法は更新幅を与える必要がなく、収束が速い。しかし逆行列を計算する必要があるので計算量が大きく1ステップあたりは遅い。</p>
        
        <h3>多クラス分類問題</h3>
        <p>出力がyes / noだけでなく３クラス以上で分類したい場合は、クラス数を\(K\)とし、クラスラベルを\(C_1,C_2, \dots C_K\)とする。
            入力\(\mathbf{x}\)がクラス\(C_k\)に分類される事後確率は
        </p>
        $$ p (C_k | \Phi) = y_k(\Phi) = \frac{exp(a_k)}{\Sigma_{j}exp(a_j)} $$
        <p>で与えらえる。このモデル化は多項ロジスティック回帰と呼ばれる。ただし、「活性」\(a_k\)は</p>
        $$ a_k = \mathbf{w}_k^T\Phi \quad (k = 1, 2 , \dots , K) $$
        <p>で与えられる。</p>
    </div>

    <footer>
        <p>© 2024 Hana Hirose. All rights reserved.</p>
    </footer>
</body>
</html>
